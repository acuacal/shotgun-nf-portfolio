\
// conf/hybrid.config
// Configuration for running the pipeline on AWS Batch (hybrid mode)

// Process-specific configurations for AWS Batch
process {
    // Default executor for processes in this profile
    executor = 'awsbatch'

    // Specify the AWS Batch Job Queue
    // Replace 'YOUR_QUEUE_NAME_HERE' with your actual AWS Batch queue name
    queue = 'YOUR_QUEUE_NAME_HERE'

    // Define a default container image if most processes use the same one
    // This can be overridden per process in the main script or modules
    // e.g., container = 'your-docker-registry/your-default-image:latest'
}

// AWS specific configurations
aws {
    // Specify the AWS region where your Batch environment is set up
    // Replace 'YOUR_AWS_REGION_HERE' with your actual AWS region (e.g., 'us-east-1')
    region = 'YOUR_AWS_REGION_HERE'

    // If using a custom AMI with AWS CLI installed at a non-standard path:
    // batch.cliPath = '/path/to/aws/cli/in/custom/ami'
}

// Docker general settings (if applicable, often implicitly handled by AWS Batch with containers)
// docker.enabled = true

// Specify S3 work directory for Nextflow (recommended for AWS Batch)
// Replace 's3://your-bucket-name/your-workdir-path' with your actual S3 path
// workDir = 's3://your-bucket-name/your-workdir-path'

// You might want to include other configurations, for example,
// specific resource allocations (cpus, memory) for certain processes or labels,
// or enabling/disabling features like Wave or Fusion if used.

// Example of process selector for specific resource needs:
// process {
//    withLabel: 'high_memory' {
//        memory = '64.GB'
//        queue = 'YOUR_HIGH_MEMORY_QUEUE_NAME_HERE' // Optional: if you have a separate queue
//    }
// }

// Ensure that your AWS credentials are configured correctly in your environment
// (e.g., via AWS CLI configuration, IAM roles for EC2, or environment variables).
// Do NOT store AWS access keys directly in this configuration file. 